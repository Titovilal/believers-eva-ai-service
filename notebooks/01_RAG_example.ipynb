{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f56ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.parsers import DoclingParser, DoclingNativeChunker\n",
    "from src.retrievers import BM25sRetriever, ChromaDBRetriever\n",
    "import os\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc08104",
   "metadata": {},
   "source": [
    "## Parse documents\n",
    "\n",
    "For this example we are going to parse and use the ESG/EFRAG documentation. This documentation is located in the `/data/ESG Documentation/EFRAG/` directory and contains PDF files related to European Financial Reporting Advisory Group (EFRAG) sustainability reporting standards.\n",
    "\n",
    "The data includes:\n",
    "- IG 1 Materiality Assessment\n",
    "- ESRS-ISSB standards interoperability guidance\n",
    "- ED_ESRS_AP5 document\n",
    "\n",
    "We'll use the DoclingParser to parse these documents and then apply different chunking strategies using TextChunker or DoclingNativeChunker. After chunking, we'll create retrievers (BM25sRetriever and ChromaDBRetriever) to efficiently store and search through this documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa30ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 files\n",
      "Sample file paths:\n",
      "../data/ESG Documentation/EFRAG/IG 1 Materiality Assessment_final.pdf\n",
      "../data/ESG Documentation/EFRAG/esrs-issb-standards-interoperability-guidance.pdf\n",
      "../data/ESG Documentation/EFRAG/ED_ESRS_AP5.pdf\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/ESG Documentation/EFRAG/\"\n",
    "# Get all files in the data_path directory and its subdirectories\n",
    "documentation_path = []\n",
    "for root, dirs, files in os.walk(data_path):\n",
    "    for file in files:\n",
    "        documentation_path.append(os.path.join(root, file))\n",
    "\n",
    "# Display the first few file paths\n",
    "print(f\"Found {len(documentation_path)} files\")\n",
    "if documentation_path:\n",
    "    print(\"Sample file paths:\")\n",
    "    for path in documentation_path[:5]:\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b969bccd",
   "metadata": {},
   "source": [
    "Define the parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4110b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = DoclingParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96901c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fcabla/Documents/projects/believers-eva/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "parsed_documents = parser.parse(documentation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42bf8d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 3 documents\n",
      "Sample parsed documents:\n",
      "First document: IG 1 Materiality Assessment_final.pdf\n",
      "of\n",
      "\n",
      "55\n",
      "\n",
      "## Disclaimer\n",
      "\n",
      "This  implementation  guida\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parsed {len(parsed_documents)} documents\")\n",
    "print(\"Sample parsed documents:\")\n",
    "print(f\"First document: {parsed_documents[0].filename}\")\n",
    "print(parsed_documents[0].text[100:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d792f78",
   "metadata": {},
   "source": [
    "## Chunk Documents for Retrieval\n",
    "\n",
    "After parsing the ESG/EFRAG documentation files, we need to prepare them for efficient retrieval. This involves chunking the documents into manageable pieces that can be indexed and searched.\n",
    "\n",
    "The chunking process is crucial because:\n",
    "- It breaks down large documents into smaller, more focused segments\n",
    "- It preserves context through metadata\n",
    "- It enables more precise retrieval of relevant information\n",
    "- It optimizes performance of retrieval systems\n",
    "\n",
    "In the following cells, we'll use DoclingNativeChunker to segment our documents and then index these chunks using both BM25sRetriever and ChromaDBRetriever to enable efficient search capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218262bb",
   "metadata": {},
   "source": [
    "Define the chunker (chunk strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbc7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = DoclingNativeChunker()\n",
    "# alternative chunker\n",
    "# chunker = TextChunker(chunk_size=1000, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c9995fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3320 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "docling_chunks = parser.chunk_documents(parsed_documents, chunker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f9bee75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 3 documents into 309 chunks\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parsed {len(parsed_documents)} documents into {len(docling_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8412af9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chunk(text=\"FAQ 15: Do the ESRS mandate to actively engage in dialogue with affected stakeholders for the materiality assessment process?\\n197. The ESRS require disclosure on the materiality assessment and its outcomes but do not mandate specific behaviour on stakeholder engagement or the due diligence process.\\n198. However, ESRS 1 paragraph 45 states that the impact materiality assessment is informed by the undertaking's due diligence process. In addition, ESRS 1 paragraph 24 points to affected stakeholders' engagement as central to the materiality assessment. Engagement with affected stakeholders is a tool that supports the undertaking's business processes (for example, due diligence) as well  as  the  management  of  sustainability  matters.  The  undertaking,  when preparing  its  sustainability  statement,  can  leverage  its  engagement  with affected stakeholders per its due diligence process, if applicable.\\n199. Stakeholder  engagement  informs  the  identification and  assessment  of material impacts. This can help the assessment of severity, likelihood and time horizons and also ensure the completeness of the material impacts identified. Refer  to  Chapter  3.5 Role  and  approach  to  stakeholders  in  the  materiality assessment .\", metadata={'file': 'IG 1 Materiality Assessment_final.pdf', 'chunk_id': 100})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docling_chunks[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f852e055",
   "metadata": {},
   "source": [
    "Now lets define the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a625515",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25s_retriever = BM25sRetriever(index_path=\"bm25s_index_notebook01\")\n",
    "chromadb_retriever = ChromaDBRetriever(persist_directory=\"chromadb_index_notebook01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9567727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [docling_chunks.text for docling_chunks in docling_chunks]\n",
    "metas = [docling_chunks.metadata for docling_chunks in docling_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84fd8342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    }
   ],
   "source": [
    "bm25s_retriever.add_documents(docs, metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ff8ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromadb_retriever.add_documents(docs, metas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e019d7c",
   "metadata": {},
   "source": [
    "Persist the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b05ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25s_retriever.save(\"bm25s_index_notebook01\")\n",
    "chromadb_retriever.save(\"chromadb_index_notebook01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702a8e04",
   "metadata": {},
   "source": [
    "## Test retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d326d",
   "metadata": {},
   "source": [
    "Some generated queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34d1685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample queries\n",
    "sample_queries = [\n",
    "    # Relevant queries\n",
    "    # \"What is double materiality?\",\n",
    "    # \"How to implement materiality assessment?\",\n",
    "    \"ESRS sustainability reporting requirements\",\n",
    "    # \"Financial materiality vs impact materiality\",\n",
    "    \"Value chain considerations in ESG reporting\",\n",
    "    # \"Stakeholder engagement in sustainability reporting\",\n",
    "    # \"EFRAG guidance on materiality assessment\",\n",
    "    \"IROs in sustainability reporting\",\n",
    "    # Less relevant queries\n",
    "    \"Carbon footprint calculation methodologies\",\n",
    "    \"ESG investment strategies\",\n",
    "    # Non-relevant queries\n",
    "    \"Recipe for chocolate cake\",\n",
    "    \"Best hiking trails in Europe\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9951ab",
   "metadata": {},
   "source": [
    "Define helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd717463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(indices, scores, docs):\n",
    "    \"\"\"Helper function to print retrieval results.\"\"\"\n",
    "    print(f\"Found {len(indices)} results:\")\n",
    "    for i, (idx, score, doc) in enumerate(zip(indices, scores, docs)):\n",
    "        # Truncate long documents for display\n",
    "        doc_display = doc[:200]\n",
    "        # doc_display = doc if len(doc) < 60 else doc[:57] + \"...\"\n",
    "        print(f\"  {i + 1}. [ID: {idx}, Score: {score:.4f}] {doc_display}\")\n",
    "\n",
    "\n",
    "def compare_retrievers(\n",
    "    query: str,\n",
    "    topk: int,\n",
    "    metadata: Optional[dict] = None,\n",
    "    threshold: Optional[float] = None,\n",
    "):\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"BM25s Results:\")\n",
    "    indices, scores, docs = bm25s_retriever.retrieve(\n",
    "        query=query,\n",
    "        top_k=topk,\n",
    "        metadata_filter=metadata,\n",
    "        # threshold=threshold*10,    # normalize threshold!\n",
    "    )\n",
    "    print_results(indices, scores, docs)\n",
    "    print(\"=========================\")\n",
    "    print(\"ChromaDB Results:\")\n",
    "    indices, scores, docs = chromadb_retriever.retrieve(\n",
    "        query=query,\n",
    "        top_k=topk,\n",
    "        metadata_filter=metadata,\n",
    "        # threshold=threshold,\n",
    "    )\n",
    "    print_results(indices, scores, docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9110dc2e",
   "metadata": {},
   "source": [
    "Test 1: What is the definition of carbon credit? Retrieving 3 chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c69ea38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the definition of carbon credit\n",
      "BM25s Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 results:\n",
      "  1. [ID: 159, Score: 6.5858] 4.1 Choices to be made for an entity starting with ISSB Standards\n",
      "Explanation, (iii) Carbon credits = Definition of carbon credit. , (iii) Carbon credits = Paragraph 36(e) of IFRS S2 requires an entit\n",
      "  2. [ID: 160, Score: 5.1806] 4.1 Choices to be made for an entity starting with ISSB Standards\n",
      "E1 should be aware that non-verified or carbon credits verified under schemes not recognised as quality standards,or carbon credits th\n",
      "  3. [ID: 153, Score: 5.1246] Section 3. ESRS to IFRS S2 (climate):  information that an entity starting with ESRS needs to know when also applying ISSB Standards to enable compliance with both sets of standards\n",
      "Explanation, (vii)\n",
      "=========================\n",
      "ChromaDB Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 results:\n",
      "  1. [ID: 159, Score: 0.6197] 4.1 Choices to be made for an entity starting with ISSB Standards\n",
      "Explanation, (iii) Carbon credits = Definition of carbon credit. , (iii) Carbon credits = Paragraph 36(e) of IFRS S2 requires an entit\n",
      "  2. [ID: 185, Score: 0.5947] Greenhouse gas removals\n",
      "Carbon credits, Reference to.IFRS S2 = . Carbon credits, TABLE 4.2.2 Requirements not covered by IFRS S2. = . ESRS E1.59 and AR61-AR63, Reference to.IFRS S2 = IFRS S2.36(e)(i)-\n",
      "  3. [ID: 153, Score: 0.5445] Section 3. ESRS to IFRS S2 (climate):  information that an entity starting with ESRS needs to know when also applying ISSB Standards to enable compliance with both sets of standards\n",
      "Explanation, (vii)\n"
     ]
    }
   ],
   "source": [
    "compare_retrievers(query=\"What is the definition of carbon credit\", topk=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8df4007",
   "metadata": {},
   "source": [
    "Test 2: What is Double Materiality? Retrieving 3 chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b203b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is double materiality?\n",
      "BM25s Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 results:\n",
      "  1. [ID: 10, Score: 2.4930] Table of contents\n",
      "materiality...............................................................................37, 1 = . FAQ 1: Is impact materiality based on materiality for the undertaking or for stake\n",
      "  2. [ID: 20, Score: 2.4515] Table of contents\n",
      "IROs?.............................................................................................................................................51 FAQ 23: Are remediation and mitig\n",
      "  3. [ID: 125, Score: 2.3326] 1.1 Materiality\n",
      "This alignment means that in assessing whether a particular disclosure is considered material in  applying  ISSB  Standards,  that  assessment  is  aligned  with  the  assessment  of  \n",
      "=========================\n",
      "ChromaDB Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 results:\n",
      "  1. [ID: 208, Score: 0.5823] ESRS E1 § 46 to 56- Double materiality as the basis for sustainability disclosures\n",
      "Double materiality is a concept which provides criteria for determination of whether a sustainability matter has to b\n",
      "  2. [ID: 30, Score: 0.5222] 2. The ESRS approach to materiality\n",
      "23. The  ESRS  require  that  the  sustainability  statement  include  sustainability information  related  to  material  IROs  identified  through  a  MA  process \n",
      "  3. [ID: 90, Score: 0.5180] FAQ 9: How to consider time horizon in the double materiality analysis?\n",
      "- 177. A sustainability matter might be material  from  an  impact  or  financial perspective over the short-, mediumor long-ter\n"
     ]
    }
   ],
   "source": [
    "compare_retrievers(\n",
    "    query=\"What is double materiality?\",\n",
    "    topk=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f464b2f0",
   "metadata": {},
   "source": [
    "Test 3: What is Double Materiality? Retrieving 3 chunks from the \"IG 1 Materiality Assessment_final.pdf\" document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a82dfab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is double materiality?\n",
      "BM25s Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 results:\n",
      "  1. [ID: 10, Score: 2.4930] Table of contents\n",
      "materiality...............................................................................37, 1 = . FAQ 1: Is impact materiality based on materiality for the undertaking or for stake\n",
      "  2. [ID: 20, Score: 2.4515] Table of contents\n",
      "IROs?.............................................................................................................................................51 FAQ 23: Are remediation and mitig\n",
      "  3. [ID: 94, Score: 2.2479] Example of severity\n",
      "If the  undertaking  concludes,  based  on qualitative criteria, that an impact connected  to  the  undertaking  sits  on  the edge dividing what is material from what is non-mater\n",
      "=========================\n",
      "ChromaDB Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 results:\n",
      "  1. [ID: 30, Score: 0.5222] 2. The ESRS approach to materiality\n",
      "23. The  ESRS  require  that  the  sustainability  statement  include  sustainability information  related  to  material  IROs  identified  through  a  MA  process \n",
      "  2. [ID: 90, Score: 0.5180] FAQ 9: How to consider time horizon in the double materiality analysis?\n",
      "- 177. A sustainability matter might be material  from  an  impact  or  financial perspective over the short-, mediumor long-ter\n",
      "  3. [ID: 5, Score: 0.4656] Table of contents\n",
      "used........................................................................................................................, 1 = 8. 2. The ESRS approach to materiality..............\n"
     ]
    }
   ],
   "source": [
    "compare_retrievers(\n",
    "    query=\"What is double materiality?\",\n",
    "    topk=3,\n",
    "    metadata={\"file\": \"IG 1 Materiality Assessment_final.pdf\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed71138",
   "metadata": {},
   "source": [
    "Test 4: Best hiking trails in Europe? Retrieving 3 chunks.\n",
    "\n",
    "This tests show how the retrievers behave with an irrelevant query. We can establish a threshold to return only the chunks that we are sure are relevant to the query. Look at the scores and compare them to the previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a776db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Best hiking trails in Europe\n",
      "BM25s Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 results:\n",
      "  1. [ID: 96, Score: 1.7557] FAQ 12: Should the materiality assessment be documented/evidenced?\n",
      "186. The ESRS do not prescribe specific documentation as this is outside its remit, but it is reasonable to expect a certain level of\n",
      "  2. [ID: 99, Score: 1.5586] FAQ 14: Will the implementation of sector-specific standards create any new subtopics or sub-subtopics to be considered in the materiality assessment?\n",
      "194. Yes, it may. The sector-specific standards w\n",
      "  3. [ID: 51, Score: 1.4647] Understanding of affected stakeholders\n",
      "in  ESRS  S1  paragraph  AR73  may  help  to  assess  whether  the  sub-subtopic 'adequate wages' is  material.  It  is  equally  important  for  the  undertakin\n",
      "=========================\n",
      "ChromaDB Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 results:\n",
      "  1. [ID: 3, Score: 0.1700] About EFRAG\n",
      "EFRAG's  mission  is  to  serve  the  European  public  interest  in  both  financial  and sustainability reporting by developing and promoting European views in the field of corporate  re\n",
      "  2. [ID: 23, Score: 0.1301] Summary in 13 key points\n",
      "(b) identification  of  actual  and  potential  IROs  related  to  sustainability matters;\n",
      "(c) assessment and  determination of the material IROs related to sustainability mat\n",
      "  3. [ID: 117, Score: 0.1281] FAQ 25: What is the relationship between taxonomy eligible activities and materiality?\n",
      "236. The  EU  Taxonomy  Regulation  and  its  Delegated  Acts  define  criteria  for  a number of economic activi\n"
     ]
    }
   ],
   "source": [
    "compare_retrievers(\n",
    "    query=\"Best hiking trails in Europe\",\n",
    "    topk=3,\n",
    "    metadata={\"file\": \"IG 1 Materiality Assessment_final.pdf\"},\n",
    "    # threshold=0.5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
